{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dranzer120/tm-nb-conventions/blob/main/Assignment_4_Political_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz28LnO5DLR_"
      },
      "source": [
        "## Naive Bayes on Political Text\n",
        "\n",
        "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W1-2m_ceDLSB"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import nltk\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# Feel free to include your text patterns functions\n",
        "# from text_functions_solutions import clean_tokenize, get_patterns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FueFUcssDUJu",
        "outputId": "d33c24bf-9fa1-48c9-c89a-eb9dd0ed283e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMrT79fvIe5_",
        "outputId": "4e47df3c-d11d-419c-93ea-38f319da6fdf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r7bfLogEx-V",
        "outputId": "ad1b06fb-c8b7-4caa-df2b-ce02afc96cd2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xBWCjZUDDLSC"
      },
      "outputs": [],
      "source": [
        "convention_db = sqlite3.connect(\"/content/drive/MyDrive/Colab Notebooks/Assignment_4/2020_Conventions.db\")\n",
        "convention_cur = convention_db.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Look at what tables are in the dababase\n",
        "convention_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "tables = convention_cur.fetchall()\n",
        "print(tables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZWdU9igGPB_",
        "outputId": "08271247-7f66-44e4-fdbe-33bf93152d69"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('conventions',)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Look at the columns in the database\n",
        "convention_cur.execute(\"PRAGMA table_info(conventions);\")\n",
        "columns = convention_cur.fetchall()\n",
        "print(columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJ3rJ4jaGkod",
        "outputId": "80deef8c-b983-4f5b-87f4-6f6e97347e22"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 'party', 'TEXT', 0, None, 0), (1, 'night', 'INTEGER', 0, None, 0), (2, 'speaker', 'TEXT', 0, None, 0), (3, 'speaker_count', 'INTEGER', 0, None, 0), (4, 'time', 'TEXT', 0, None, 0), (5, 'text', 'TEXT', 0, None, 0), (6, 'text_len', 'TEXT', 0, None, 0), (7, 'file', 'TEXT', 0, None, 0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KoW0QoTDLSD"
      },
      "source": [
        "### Part 1: Exploratory Naive Bayes\n",
        "\n",
        "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text\n",
        "for each party and prepare it for use in Naive Bayes.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "MIWbqKcPDLSD"
      },
      "outputs": [],
      "source": [
        "convention_data = []\n",
        "\n",
        "# fill this list up with items that are themselves lists. The\n",
        "# first element in the sublist should be the cleaned and tokenized\n",
        "# text in a single string. The second element should be the party.\n",
        "\n",
        "query_results = convention_cur.execute(\n",
        "                            '''\n",
        "                            SELECT text, party\n",
        "                            FROM conventions\n",
        "                            ''')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = ' '.join([word.lower() for word in word_tokenize(text) if word.isalpha()])\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "for row in query_results:\n",
        "    speech_text, party = row\n",
        "    cleaned_text = preprocess_text(speech_text)\n",
        "    convention_data.append([cleaned_text, party])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnfkB9GgDLSD"
      },
      "source": [
        "Let's look at some random entries and see if they look right."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF_xKgZuDLSE",
        "outputId": "0c7b3f36-0ad5-436d-8bcd-ec7597668fe5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['joe biden said living season darkness president trump said joe biden sees american darkness see american greatness challenging times country needs president believes america believes boundless capacity american people meet challenge defeat foe defend freedoms hold dear america needs four years president donald trump white house go allow say word families communities path hurricane laura prayers tonight administration working closely authorities states impacted fema mobilized resources supplies harm way',\n",
              "  'Republican'],\n",
              " ['hi mike pompeo speaking beautiful jerusalem looking old city big job susan husband nick dad susan nick safe freedoms secure president trump put america first vision action may made popular every foreign capital worked president trump understands great fellow kansan president eisenhower said cherish justly desire children securing peace first indeed primary constitutional function national government ensuring family mine safe enjoy freedom live work learn worship choose delivering duty keep us safe freedoms intact president led bold initiatives nearly every corner world china pulled back curtain predatory aggression chinese communist party',\n",
              "  'Republican'],\n",
              " ['started tea party years american civil war civil unrest division separated countrymen two opposing camps one determined keep people enslaved determined see people free elizabeth cady stanton lucretia mott felt call fight freedom selected delegates convention upon arrival told could speak vote event july mott stanton three women met tea end day formed coalition sole purpose gaining right women vote turn would free fight freedoms others women across america united formed activist groups working tirelessly win vote american women unconquerable susan anthony became one visible leaders women suffrage registered voted every republican ballot',\n",
              "  'Republican'],\n",
              " ['people assume democrat anymore must republican must conservative still consider liberal liberalism changed fit anymore',\n",
              "  'Republican'],\n",
              " ['hi name brayden harrington years old without joe biden talking today months ago met new hampshire told members club stutter really amazing hear someone like became vice president told book poems yeats would read loud practice showed marks addresses make easier say loud thing today talking today future future',\n",
              "  'Democratic'],\n",
              " ['ladies gentlemen please welcome first lady united states melania trump',\n",
              "  'Republican'],\n",
              " ['think upcoming election people need think better family', 'Republican'],\n",
              " ['love mamala', 'Democratic'],\n",
              " ['hey everybody kamala go stage later tonight want talk importance voting know many plan vote year amidst excitement enthusiasm election also heard obstacles misinformation folks making harder cast ballot think need ask want us vote much effort silence voices answer vote things change vote things get better vote address need people treated dignity respect country us needs plan voting plan joe want make sure prepared text vote help come plan remember deadlines get ready vote community',\n",
              "  'Democratic'],\n",
              " ['think places make neighborhood feel like home barbershop catch latest neighborhood news get hair cut restaurant know order heart art studio creative guy great idea ton hustle turned abandoned building second home entire community economists tell small businesses like one critically important recovery also plain important without places call home thing joe biden understands donald trump never never talk economy stock market whether find work really means something instead feeling like supposed grateful get paycheck rep',\n",
              "  'Democratic']]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "random.choices(convention_data,k=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tKsjwbsDLSF"
      },
      "source": [
        "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK0wVWcHDLSF",
        "outputId": "e613c6fa-b0cd-440f-d5b9-4dd4714eb588"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With a word cutoff of 5, we have 2236 as features in the model.\n"
          ]
        }
      ],
      "source": [
        "word_cutoff = 5\n",
        "\n",
        "tokens = [w for t, p in convention_data for w in t.split()]\n",
        "\n",
        "word_dist = nltk.FreqDist(tokens)\n",
        "\n",
        "feature_words = set()\n",
        "\n",
        "for word, count in word_dist.items() :\n",
        "    if count > word_cutoff :\n",
        "        feature_words.add(word)\n",
        "\n",
        "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Ina2rJtrDLSF"
      },
      "outputs": [],
      "source": [
        "def conv_features(text,fw) :\n",
        "    \"\"\"Given some text, this returns a dictionary holding the\n",
        "       feature words.\n",
        "\n",
        "       Args:\n",
        "            * text: a piece of text in a continuous string. Assumes\n",
        "            text has been cleaned and case folded.\n",
        "            * fw: the *feature words* that we're considering. A word\n",
        "            in `text` must be in fw in order to be returned. This\n",
        "            prevents us from considering very rarely occurring words.\n",
        "\n",
        "       Returns:\n",
        "            A dictionary with the words in `text` that appear in `fw`.\n",
        "            Words are only counted once.\n",
        "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
        "            then this would return a dictionary of\n",
        "            {'quick' : True,\n",
        "             'fox' :    True}\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Your code here\n",
        "\n",
        "    tokens = text.split()\n",
        "\n",
        "    ret_dict = dict()\n",
        "\n",
        "    # Iterate over the tokens and check if they are in feature_words\n",
        "    for word in set(tokens):\n",
        "        if word in fw:\n",
        "            ret_dict[word] = True\n",
        "\n",
        "    return(ret_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert(len(feature_words)>0)\n",
        "assert(conv_features(\"obama was the president\",feature_words)==\n",
        "       {'obama':True,'president':True})\n",
        "assert(conv_features(\"some people in america are citizens\",feature_words)==\n",
        "                     {'people':True,'america':True,\"citizens\":True})"
      ],
      "metadata": {
        "id": "K_5ChfZXRjcJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrjC4FKTDLSG"
      },
      "source": [
        "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "LSBflPkJDLSG"
      },
      "outputs": [],
      "source": [
        "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "lB3kQ2NLDLSG"
      },
      "outputs": [],
      "source": [
        "random.seed(20220507)\n",
        "random.shuffle(featuresets)\n",
        "\n",
        "test_size = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N2lJuC0DLSH",
        "outputId": "751aef0e-aeca-4192-dd6c-a08c315d30cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.494\n"
          ]
        }
      ],
      "source": [
        "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6nn8L7ZDLSH",
        "outputId": "ace61b01-68e2-4ea1-d880-108d02e68dd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "                   china = True           Republ : Democr =     27.1 : 1.0\n",
            "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
            "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
            "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
            "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
            "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
            "                supports = True           Republ : Democr =     17.1 : 1.0\n",
            "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
            "                   media = True           Republ : Democr =     15.8 : 1.0\n",
            "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
            "               countries = True           Republ : Democr =     13.0 : 1.0\n",
            "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
            "                  defund = True           Republ : Democr =     13.0 : 1.0\n",
            "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
            "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
            "                religion = True           Republ : Democr =     13.0 : 1.0\n",
            "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
            "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
            "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
            "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
            "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
            "              department = True           Republ : Democr =     10.9 : 1.0\n",
            "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
            "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
            "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
          ]
        }
      ],
      "source": [
        "classifier.show_most_informative_features(25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLiO9LiQDLSH"
      },
      "source": [
        "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
        "\n",
        "### My Observations\n",
        "Based on the result above, it seems like the word \"china\" and \"climate\" are more associated with democrats. But the rest of the words are more associated with the Repbulicans.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAY7hfEyDLSH"
      },
      "source": [
        "## Part 2: Classifying Congressional Tweets\n",
        "\n",
        "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
        "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
        "give you the query I used to pull out the tweets. Note that this DB has some big tables and\n",
        "is unindexed, so the query takes a minute or two to run on my machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "E3R1qPI2DLSH"
      },
      "outputs": [],
      "source": [
        "cong_db = sqlite3.connect(\"/content/drive/MyDrive/Colab Notebooks/Assignment_4/congressional_data.db\")\n",
        "cong_cur = cong_db.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "JDsCJVgUDLSI"
      },
      "outputs": [],
      "source": [
        "results = cong_cur.execute(\n",
        "        '''\n",
        "           SELECT DISTINCT\n",
        "                  cd.candidate,\n",
        "                  cd.party,\n",
        "                  tw.tweet_text\n",
        "           FROM candidate_data cd\n",
        "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle\n",
        "               AND cd.candidate == tw.candidate\n",
        "               AND cd.district == tw.district\n",
        "           WHERE cd.party in ('Republican','Democratic')\n",
        "               AND tw.tweet_text NOT LIKE '%RT%'\n",
        "        ''')\n",
        "\n",
        "results = list(results) # Just to store it, since the query is time consuming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWzAgZKADLSI",
        "outputId": "1f4474fe-89e3-423d-b802-32705cb0ba50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1221141 tweets.\n"
          ]
        }
      ],
      "source": [
        "tweet_data = []\n",
        "\n",
        "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
        "# Note that this may take a bit of time, since we have a lot of tweets.\n",
        "\n",
        "# Preprocess function to clean and tokenize tweets\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_tweet_text(text):\n",
        "    # Decode byte string to regular string\n",
        "    text = text.decode('utf-8')\n",
        "    text = ' '.join([word.lower() for word in word_tokenize(text) if word.isalpha()])\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "# Process the results and store preprocessed data in tweet_data\n",
        "for row in results:\n",
        "    candidate, party, tweet_text = row\n",
        "    cleaned_tokens = preprocess_tweet_text(tweet_text)\n",
        "    tweet_data.append([cleaned_tokens, party])\n",
        "\n",
        "print(f\"Processed {len(tweet_data)} tweets.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pczYR5WDLSI"
      },
      "source": [
        "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "rToTR95eDLSI"
      },
      "outputs": [],
      "source": [
        "random.seed(20201014)\n",
        "\n",
        "tweet_data_sample = random.choices(tweet_data,k=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkpeR1gIDLSI",
        "outputId": "7c2b7876-088e-494a-e169-b888168b4829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's our (cleaned) tweet: mass shooting las vegas horrific act violence victims families thoughts prayers\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: early morning traveltuesday leaving dc http\n",
            "Actual party is Republican and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: moderates iraq amp syria civilians enemies sides conflict assist either\n",
            "Actual party is Republican and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: rt natsecaction national security veterans demanding answers release confidential national security\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: buildthatwall https\n",
            "Actual party is Republican and our classifer says Democratic.\n",
            "\n",
            "Here's our (cleaned) tweet: glad attend assure everyone could majority americans still stand traditional allies\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: cnn everyone wraps flag patriotism avoid discussion racism injustice kneeling honoring troops\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: applaud president trump decision send national guard protect border congress support president including fully funding wall time stop playing politics national security united states fundthewall nationalguard\n",
            "Actual party is Republican and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: congress considers disaster relief spending year must include funding california fire relief listen remarks house floor https\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: proud support oss helped vanquish malevolent enemies free ever faced https\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for tweet, party in tweet_data_sample :\n",
        "    estimated_party = classifier.classify(conv_features(tweet, feature_words))\n",
        "    # Fill in the right-hand side above with code that estimates the actual party\n",
        "\n",
        "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
        "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
        "    print(\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN5SxoaODLSJ"
      },
      "source": [
        "Now that we've looked at it some, let's score a bunch and see how we're doing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "n2M1NgxrDLSJ"
      },
      "outputs": [],
      "source": [
        "# dictionary of counts by actual party and estimated party.\n",
        "# first key is actual, second is estimated\n",
        "parties = ['Republican','Democratic']\n",
        "results = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "for p in parties :\n",
        "    for p1 in parties :\n",
        "        results[p][p1] = 0\n",
        "\n",
        "\n",
        "num_to_score = 10000\n",
        "random.shuffle(tweet_data)\n",
        "\n",
        "for idx, tp in enumerate(tweet_data) :\n",
        "    tweet, party = tp\n",
        "    # Now do the same thing as above, but we store the results rather\n",
        "    # than printing them.\n",
        "    tweet_features = conv_features(tweet, feature_words)\n",
        "\n",
        "    # get the estimated party\n",
        "    estimated_party = classifier.classify(tweet_features)\n",
        "\n",
        "    results[party][estimated_party] += 1\n",
        "\n",
        "    if idx > num_to_score :\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWwRJ3SFDLSJ",
        "outputId": "bc4101a2-677c-4814-d754-1f75ba01cfc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>()>,\n",
              "            {'Republican': defaultdict(int,\n",
              "                         {'Republican': 3663, 'Democratic': 477}),\n",
              "             'Democratic': defaultdict(int,\n",
              "                         {'Republican': 5090, 'Democratic': 772})})"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5tQHE3fDLSJ"
      },
      "source": [
        "### Reflections\n",
        "\n",
        "Based on the results, it seems like the classifier is more biased in predicting republican. And this actually aligns with our sample results as well. Where out of the 10 samples, our classifier predicted 8 to be republican."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6dsi4ETr8JZn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}